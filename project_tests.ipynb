{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "aa0277ab-ce8e-4ffc-af84-0eeef140caa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.losses import sparse_categorical_crossentropy\n",
    "from keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "aa32e4e3-4c6f-429d-be4b-bfa2221babde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _test_model(model, input_shape, output_sequence_length, french_vocab_size):\n",
    "    #if isinstance(model, Sequential):\n",
    "    #    model = model.model\n",
    "\n",
    "    assert model.input_shape == (None, *input_shape[1:]),\\\n",
    "        'Wrong input shape. Found input shape {} using parameter input_shape={}'.format(model.input_shape, input_shape)\n",
    "\n",
    "    assert model.output_shape == (None, output_sequence_length, french_vocab_size),\\\n",
    "        'Wrong output shape. Found output shape {} using parameters output_sequence_length={} and french_vocab_size={}'\\\n",
    "            .format(model.output_shape, output_sequence_length, french_vocab_size)\n",
    "\n",
    "    #assert len(model.loss) > 0,\\\n",
    "     #   'No loss function set.  Apply the `compile` function to the model.'\n",
    "\n",
    "    assert (model.loss == sparse_categorical_crossentropy),\\\n",
    "        'Not using `sparse_categorical_crossentropy` function for loss.'\n",
    "\n",
    "\n",
    "def test_tokenize(tokenize):\n",
    "    sentences = [\n",
    "        'The quick brown fox jumps over the lazy dog .',\n",
    "        'By Jove , my quick study of lexicography won a prize .',\n",
    "        'This is a short sentence .']\n",
    "    tokenized_sentences, tokenizer = tokenize(sentences)\n",
    "    assert tokenized_sentences == tokenizer.texts_to_sequences(sentences),\\\n",
    "        'Tokenizer returned and doesn\\'t generate the same sentences as the tokenized sentences returned. '\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4fb4eabe-75e3-4ef3-bced-088f430d31cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_pad(pad):\n",
    "    tokens = [\n",
    "        [i for i in range(4)],\n",
    "        [i for i in range(6)],\n",
    "        [i for i in range(3)]]\n",
    "    padded_tokens = pad(tokens)\n",
    "    padding_id = padded_tokens[0][-1]\n",
    "    true_padded_tokens = np.array([\n",
    "        [i for i in range(4)] + [padding_id]*2,\n",
    "        [i for i in range(6)],\n",
    "        [i for i in range(3)] + [padding_id]*3])\n",
    "    assert isinstance(padded_tokens, np.ndarray),\\\n",
    "        'Pad returned the wrong type.  Found {} type, expected numpy array type.'\n",
    "    assert np.all(padded_tokens == true_padded_tokens), 'Pad returned the wrong results.'\n",
    "\n",
    "    padded_tokens_using_length = pad(tokens, 9)\n",
    "    assert np.all(padded_tokens_using_length == np.concatenate((true_padded_tokens, np.full((3, 3), padding_id)), axis=1)),\\\n",
    "        'Using length argument return incorrect results'\n",
    "\n",
    "\n",
    "def test_simple_model(simple_model):\n",
    "    input_shape = (137861, 21, 1)\n",
    "    output_sequence_length = 21\n",
    "    english_vocab_size = 199\n",
    "    french_vocab_size = 344\n",
    "\n",
    "    model = simple_model(input_shape, output_sequence_length, english_vocab_size, french_vocab_size)\n",
    "    _test_model(model, input_shape, output_sequence_length, french_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd0fafcd-7a59-4fef-a91e-38e44fb8731e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_embed_model(embed_model):\n",
    "    input_shape = (137861, 21, 1)\n",
    "    output_sequence_length = 21\n",
    "    english_vocab_size = 199\n",
    "    french_vocab_size = 344\n",
    "\n",
    "    model = embed_model(input_shape, output_sequence_length, english_vocab_size, french_vocab_size)\n",
    "    _test_model(model, input_shape, output_sequence_length, french_vocab_size)\n",
    "\n",
    "\n",
    "def test_encdec_model(encdec_model):\n",
    "    input_shape = (137861, 15, 1)\n",
    "    output_sequence_length = 21\n",
    "    english_vocab_size = 199\n",
    "    french_vocab_size = 344\n",
    "\n",
    "    model = encdec_model(input_shape, output_sequence_length, english_vocab_size, french_vocab_size)\n",
    "    _test_model(model, input_shape, output_sequence_length, french_vocab_size)\n",
    "\n",
    "\n",
    "def test_bd_model(bd_model):\n",
    "    input_shape = (137861, 21, 1)\n",
    "    output_sequence_length = 21\n",
    "    english_vocab_size = 199\n",
    "    french_vocab_size = 344\n",
    "\n",
    "    model = bd_model(input_shape, output_sequence_length, english_vocab_size, french_vocab_size)\n",
    "    _test_model(model, input_shape, output_sequence_length, french_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d47af8f5-dd9e-47c2-bee9-c3bc0525e72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model_final(model_final):\n",
    "    input_shape = (137861, 15)\n",
    "    output_sequence_length = 21\n",
    "    english_vocab_size = 199\n",
    "    french_vocab_size = 344\n",
    "\n",
    "    model = model_final(input_shape, output_sequence_length, english_vocab_size, french_vocab_size)\n",
    "    _test_model(model, input_shape, output_sequence_length, french_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b5d98a-fcaf-4e6e-a60b-d8940972c4e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
