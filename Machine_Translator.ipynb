{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7ff3c97-2094-4307-8223-a1f0ab559c6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%aimport helper, tests\n",
    "%autoreload 1\n",
    "%run project_tests.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb3eadd7-82f2-4609-8073-b8fbe0b40ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "import helper\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import GRU, Input, Dense, TimeDistributed, Activation, RepeatVector, Bidirectional, Dropout, LSTM\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from keras.optimizers import Adam\n",
    "from keras.losses import sparse_categorical_crossentropy\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "503376a0-60be-4f34-b33f-d81cac2fe812",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path):\n",
    "    \"\"\"\n",
    "    Load dataset\n",
    "    \"\"\"\n",
    "    input_file = os.path.join(path)\n",
    "    with open(input_file, \"r\") as f:\n",
    "        data = f.read()\n",
    "\n",
    "    return data.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d8c7fd61-bb04-4e05-8304-418a0b2f4fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load English data\n",
    "english_sentences = load_data('small_vocab_en.txt')\n",
    "#Load French data\n",
    "french_sentences = load_data('small_vocab_fr.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "59005b05-53af-41b3-80e4-83e7c643ead0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English sample 1:  new jersey is sometimes quiet during autumn , and it is snowy in april .\n",
      "French sample 1:  new jersey est parfois calme pendant l' automne , et il est neigeux en avril .\n",
      "\n",
      "English sample 2:  the united states is usually chilly during july , and it is usually freezing in november .\n",
      "French sample 2:  les Ã©tats-unis est gÃ©nÃ©ralement froid en juillet , et il gÃ¨le habituellement en novembre .\n",
      "\n",
      "English sample 3:  california is usually quiet during march , and it is usually hot in june .\n",
      "French sample 3:  california est gÃ©nÃ©ralement calme en mars , et il est gÃ©nÃ©ralement chaud en juin .\n",
      "\n",
      "English sample 4:  the united states is sometimes mild during june , and it is cold in september .\n",
      "French sample 4:  les Ã©tats-unis est parfois lÃ©gÃ¨re en juin , et il fait froid en septembre .\n",
      "\n",
      "English sample 5:  your least liked fruit is the grape , but my least liked is the apple .\n",
      "French sample 5:  votre moins aimÃ© fruit est le raisin , mais mon moins aimÃ© est la pomme .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Check the first 5 lines from each file\n",
    "for i in range(5):\n",
    "    print('English sample {}:  {}'.format(i + 1, english_sentences[i]))\n",
    "    print('French sample {}:  {}\\n'.format(i + 1, french_sentences[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "165c60e6-9f5a-4ddb-95fb-b0f3eaea9381",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1823250 English words.\n",
      "227 Unique English words\n",
      "10 Most common words in the English dataset:\n",
      "\"is\" \",\" \".\" \"in\" \"it\" \"during\" \"the\" \"but\" \"and\" \"sometimes\"\n",
      "10 Most common words in the French dataset:\n",
      "\"est\" \".\" \",\" \"en\" \"il\" \"les\" \"mais\" \"et\" \"la\" \"parfois\"\n"
     ]
    }
   ],
   "source": [
    "#Check the complexity of the dataset by checking the words\n",
    "english_words_counter = collections.Counter([word for sentence in english_sentences for word in sentence.split()])\n",
    "french_words_counter = collections.Counter([word for sentence in french_sentences for word in sentence.split()])\n",
    "\n",
    "print('{} English words.'.format(len([word for sentence in english_sentences for word in sentence.split()])))\n",
    "print('{} Unique English words'.format(len(english_words_counter)))\n",
    "print('10 Most common words in the English dataset:')\n",
    "print('\"' + '\" \"'.join(list(zip(*english_words_counter.most_common(10)))[0]) + '\"')\n",
    "print('10 Most common words in the French dataset:')\n",
    "print('\"' + '\" \"'.join(list(zip(*french_words_counter.most_common(10)))[0]) + '\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7accafd1-98e3-4027-b0d7-70f1c30704a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function for tokenizing\n",
    "def tokenize(sentences):\n",
    "    \"\"\"\n",
    "    Tokenizes sentences\n",
    "    param sentences: List of sentences/string to be tokenized\n",
    "    return: Tuple of tokenized x data and the tokenizer used to tokenize x\n",
    "    \"\"\"\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(sentences)\n",
    "    return tokenizer.texts_to_sequences(sentences),tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ed54a295-913c-496a-9ce7-3704185a6d51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'the': 1, 'quick': 2, 'a': 3, 'brown': 4, 'fox': 5, 'jumps': 6, 'over': 7, 'lazy': 8, 'dog': 9, 'by': 10, 'jove': 11, 'my': 12, 'study': 13, 'of': 14, 'lexicography': 15, 'won': 16, 'prize': 17, 'this': 18, 'is': 19, 'short': 20, 'sentence': 21}\n",
      "\n",
      "\n",
      "Sequence 1 in x\n",
      "   Input:  The quick brown fox jumps over the lazy dog .\n",
      "   Output:  [1, 2, 4, 5, 6, 7, 1, 8, 9]\n",
      "Sequence 2 in x\n",
      "   Input:  By Jove , my quick study of lexicography won a prize .\n",
      "   Output:  [10, 11, 12, 2, 13, 14, 15, 16, 3, 17]\n",
      "Sequence 3 in x\n",
      "   Input:  This is a short sentence .\n",
      "   Output:  [18, 19, 3, 20, 21]\n"
     ]
    }
   ],
   "source": [
    "#Test the tokenize function\n",
    "test_tokenize(tokenize)\n",
    "\n",
    "#Tokenize an example\n",
    "text_sentences = ['The quick brown fox jumps over the lazy dog .','By Jove , my quick study of lexicography won a prize .','This is a short sentence .']\n",
    "text_tokenized, text_tokenizer = tokenize(text_sentences)\n",
    "print(text_tokenizer.word_index)\n",
    "print('\\n')\n",
    "for i,(input, output) in enumerate(zip(text_sentences, text_tokenized)):\n",
    "    print(f'Sequence {i + 1} in x')\n",
    "    print(f'   Input:  {input}')\n",
    "    print(f'   Output:  {output}')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2cc6b783-e6a4-4a6d-b66c-d2a04113b919",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pad each sequence to be the same length\n",
    "\n",
    "#Function for padding\n",
    "def pad(list_to_pad,length=None):\n",
    "    \"\"\"\n",
    "    Pad list_to_pad\n",
    "    param list_to_pad: List of sequences.\n",
    "    param length: Length to pad the sequence to.  If None, use length of longest sequence in x.\n",
    "    return: Padded numpy array of sequences\n",
    "    \"\"\"\n",
    "    answer = pad_sequences(list_to_pad,maxlen=length,padding='post')\n",
    "    return answer\n",
    "\n",
    "#Test the pad function\n",
    "#test_pad(pad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bb995711-92a9-4822-8fbd-7d89af9bc529",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence 1 in x\n",
      "Input: [1 2 4 5 6 7 1 8 9]\n",
      "Output: [1 2 4 5 6 7 1 8 9 0]\n",
      "Sequence 2 in x\n",
      "Input: [10 11 12  2 13 14 15 16  3 17]\n",
      "Output: [10 11 12  2 13 14 15 16  3 17]\n",
      "Sequence 3 in x\n",
      "Input: [18 19  3 20 21]\n",
      "Output: [18 19  3 20 21  0  0  0  0  0]\n"
     ]
    }
   ],
   "source": [
    "#Pad the tokenized output\n",
    "test_run = pad(text_tokenized)\n",
    "for i,(token_sent,pad_sent) in enumerate(zip(text_tokenized,test_run)):\n",
    "    print(f'Sequence {i + 1} in x')\n",
    "    print(f'Input: {np.array(token_sent)}')\n",
    "    print(f'Output: {pad_sent}') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "21fad681-ba6a-4aab-a35b-a9af67a07f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function for creating a preprocess pipeline\n",
    "def preprocess(x,y):\n",
    "    \"\"\"\n",
    "    Preprocess x and y\n",
    "    x: Feature list of sentences\n",
    "    y: Label list of sentences\n",
    "    return a tuple of (Preprocessed x, Preprocessed y, x tokenizer, y tokenizer)\n",
    "    \"\"\"\n",
    "    preprocess_x, x_tk = tokenize(x)\n",
    "    preprocess_y, y_tk = tokenize(y)\n",
    "\n",
    "    preprocess_x = pad(preprocess_x)\n",
    "    preprocess_y = pad(preprocess_y)\n",
    "\n",
    "    # Keras's sparse_categorical_crossentropy function requires the labels to be in 3 dimensions\n",
    "    preprocess_y = preprocess_y.reshape(*preprocess_y.shape, 1)\n",
    "\n",
    "    return preprocess_x, preprocess_y, x_tk, y_tk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e31a9ee9-688f-4733-8f64-ae2997214aaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Preprocessed\n",
      "Max English sentence length: 15\n",
      "Max French sentence length: 21\n",
      "English vocabulary size: 199\n",
      "French vocabulary size: 345\n"
     ]
    }
   ],
   "source": [
    "#Preprocess the english and test_sentences\n",
    "preproc_english_sentences, preproc_french_sentences, english_tokenizer, french_tokenizer = preprocess(english_sentences, french_sentences)\n",
    "\n",
    "max_english_sequence_length = preproc_english_sentences.shape[1]\n",
    "max_french_sequence_length = preproc_french_sentences.shape[1]\n",
    "\n",
    "english_vocab_size = len(english_tokenizer.word_index)\n",
    "french_vocab_size = len(french_tokenizer.word_index)\n",
    "\n",
    "print('Data Preprocessed')\n",
    "print(\"Max English sentence length:\", max_english_sequence_length)\n",
    "print(\"Max French sentence length:\", max_french_sequence_length)\n",
    "print(\"English vocabulary size:\", english_vocab_size)\n",
    "print(\"French vocabulary size:\", french_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8f1e1109-2f15-4f65-982e-a78bb8cc4d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a function  to map word ids back to text\n",
    "def logits_to_text(logits, tokenizer):\n",
    "    \"\"\"\n",
    "    Turn logits from a neural network into text using the tokenizer\n",
    "    :param logits: Logits from a neural network\n",
    "    :param tokenizer: Keras Tokenizer fit on the labels\n",
    "    :return: String that represents the text of the logits\n",
    "    \"\"\"\n",
    "    index_to_words = {id: word for word, id in tokenizer.word_index.items()}\n",
    "    index_to_words[0] = '<PAD>'\n",
    "\n",
    "    return ' '.join([index_to_words[prediction] for prediction in np.argmax(logits, 1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "ae33f8b0-b018-4ff1-afee-4b6f54de4362",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_model(input_shape,output_sequence_length,english_vocab_size,french_vocab_size):\n",
    "    \"\"\"\n",
    "    Build and train a basic RNN on x ans y\n",
    "    param input_shape: Tuple of the input shape\n",
    "    param output_sequence_length: Length of output sequence\n",
    "    param english_vocab_size: Numbe of unique english words in the dataset\n",
    "    param french_vocab_size: Number of  unique french words in the dataset\n",
    "    return: Keras model built\n",
    "    \"\"\"\n",
    "    #Build the layers\n",
    "    learning_rate = 0.005\n",
    "    model = Sequential()\n",
    "    model.add(GRU(256,input_shape=input_shape[1:],return_sequences=True))\n",
    "    model.add(TimeDistributed(Dense(1024, activation='relu')))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(TimeDistributed(Dense(french_vocab_size, activation='softmax'))) \n",
    "\n",
    "    #Compile the model\n",
    "    model.compile(loss=sparse_categorical_crossentropy,\n",
    "                  optimizer=Adam(learning_rate),\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "083e7f7e-0aa6-49ce-a6df-8f1f60014b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test the simple_model function\n",
    "test_simple_model(simple_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "da2a5b3f-3b24-4730-8149-633ce2fbf9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshaping the input to work with a basic RNN\n",
    "tmp_x = pad(preproc_english_sentences, max_french_sequence_length)\n",
    "tmp_x = tmp_x.reshape((-1, preproc_french_sentences.shape[-2], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "612471bb-e1a8-4345-abb7-86855019a079",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(tmp_x, preproc_french_sentences, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "2bd47632-1a2d-482d-89d0-4a570d9b435f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_72\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_72\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ gru_80 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">198,912</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ time_distributed_134                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">263,168</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)                    │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_67 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ time_distributed_135                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">345</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">353,625</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)                    │                             │                 │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ gru_80 (\u001b[38;5;33mGRU\u001b[0m)                         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m21\u001b[0m, \u001b[38;5;34m256\u001b[0m)             │         \u001b[38;5;34m198,912\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ time_distributed_134                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m21\u001b[0m, \u001b[38;5;34m1024\u001b[0m)            │         \u001b[38;5;34m263,168\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)                    │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_67 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m21\u001b[0m, \u001b[38;5;34m1024\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ time_distributed_135                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m21\u001b[0m, \u001b[38;5;34m345\u001b[0m)             │         \u001b[38;5;34m353,625\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)                    │                             │                 │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">815,705</span> (3.11 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m815,705\u001b[0m (3.11 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">815,705</span> (3.11 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m815,705\u001b[0m (3.11 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Epoch 1/10\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 959ms/step - accuracy: 0.4203 - loss: 2.9953 - val_accuracy: 0.6008 - val_loss: 1.5159\n",
      "Epoch 2/10\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 922ms/step - accuracy: 0.5977 - loss: 1.4886 - val_accuracy: 0.6406 - val_loss: 1.2421\n",
      "Epoch 3/10\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 927ms/step - accuracy: 0.6333 - loss: 1.2676 - val_accuracy: 0.6684 - val_loss: 1.1255\n",
      "Epoch 4/10\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 933ms/step - accuracy: 0.6550 - loss: 1.1631 - val_accuracy: 0.6743 - val_loss: 1.0651\n",
      "Epoch 5/10\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 931ms/step - accuracy: 0.6665 - loss: 1.0982 - val_accuracy: 0.6910 - val_loss: 0.9864\n",
      "Epoch 6/10\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 930ms/step - accuracy: 0.6783 - loss: 1.0324 - val_accuracy: 0.6984 - val_loss: 0.9415\n",
      "Epoch 7/10\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 928ms/step - accuracy: 0.6859 - loss: 0.9937 - val_accuracy: 0.6974 - val_loss: 0.9160\n",
      "Epoch 8/10\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 1s/step - accuracy: 0.6927 - loss: 0.9565 - val_accuracy: 0.7187 - val_loss: 0.8544\n",
      "Epoch 9/10\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 913ms/step - accuracy: 0.7040 - loss: 0.9111 - val_accuracy: 0.7220 - val_loss: 0.8278\n",
      "Epoch 10/10\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 946ms/step - accuracy: 0.6912 - loss: 0.9382 - val_accuracy: 0.7039 - val_loss: 0.8749\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1a0598fca10>"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Train your neural network\n",
    "simple_rnn_model = simple_model(tmp_x.shape,max_french_sequence_length,english_vocab_size,french_vocab_size)\n",
    "\n",
    "print(simple_rnn_model.summary())\n",
    "\n",
    "simple_rnn_model.fit(X_train[:80000],y_train[:80000],batch_size=1024,epochs=10,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "35037ccc-b026-4c79-948d-ba9b739a441c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction:\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 868ms/step\n",
      "new jersey est parfois calme en mois de mai et il est en en <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "\n",
      "Correct Translation:\n",
      "[\"new jersey est parfois calme pendant l' automne , et il est neigeux en avril .\"]\n",
      "\n",
      "Original text:\n",
      "['new jersey is sometimes quiet during autumn , and it is snowy in april .']\n"
     ]
    }
   ],
   "source": [
    "# Print your predictions\n",
    "print(\"Prediction:\")\n",
    "print(logits_to_text(simple_rnn_model.predict(tmp_x[:1])[0], french_tokenizer))\n",
    "\n",
    "print(\"\\nCorrect Translation:\")\n",
    "print(french_sentences[:1])\n",
    "\n",
    "print(\"\\nOriginal text:\")\n",
    "print(english_sentences[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "12f516ca-bc0c-4c0d-967b-dbb3ad4ec040",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's try a 2nd model using word embedding with the RNNs\n",
    "def embed_model(input_shape, output_sequence_length, english_vocab_size, french_vocab_size):\n",
    "    \"\"\"\n",
    "    Build and train an RNN model using word embedding on x ans y\n",
    "    param input_shape: Tuple of the input shape\n",
    "    param output_sequence_length: Length of output sequence\n",
    "    param english_vocab_size: Numbe of unique english words in the dataset\n",
    "    param french_vocab_size: Number of  unique french words in the dataset\n",
    "    return: Keras model built\n",
    "    \"\"\"\n",
    "    #Build the layers\n",
    "    learning_rate = 0.005\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(english_vocab_size, 256, input_length=input_shape[1], input_shape=input_shape[1:]))\n",
    "    model.add(GRU(256,return_sequences=True))\n",
    "    model.add(TimeDistributed(Dense(1024, activation='relu')))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(TimeDistributed(Dense(french_vocab_size, activation='softmax'))) \n",
    "\n",
    "    #Compile the model\n",
    "    model.compile(loss=sparse_categorical_crossentropy,\n",
    "                  optimizer=Adam(learning_rate),\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "f5c1cb7d-a7ba-4252-af0d-ac93baf841b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Olurotimi Ajayi\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "#Test the embed_model function\n",
    "test_embed_model(simple_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "10475b26-cabd-4baa-bed2-992f7ed714e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reshape the input\n",
    "tmp_x = pad(preproc_english_sentences,preproc_french_sentences.shape[1])\n",
    "tmp_x = tmp_x.reshape((-1, preproc_french_sentences.shape[-2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "18135878-63ee-4f0d-b9af-084ce7d9e7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(tmp_x, preproc_french_sentences, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "4bddcada-755c-4ab8-b0b8-cfd15adecf18",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Olurotimi Ajayi\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Olurotimi Ajayi\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "# TODO: Train the neural network\n",
    "embed_rnn_model = embed_model(tmp_x.shape,preproc_french_sentences.shape[1],len(english_tokenizer.word_index)+1,len(french_tokenizer.word_index)+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "d702a1c0-f9fb-4109-907b-24ae2b1c94cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_76\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_76\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ embedding_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)             │          <span style=\"color: #00af00; text-decoration-color: #00af00\">51,200</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ gru_84 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">394,752</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ time_distributed_142                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">263,168</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)                    │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_71 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ time_distributed_143                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">346</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">354,650</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)                    │                             │                 │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ embedding_14 (\u001b[38;5;33mEmbedding\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m21\u001b[0m, \u001b[38;5;34m256\u001b[0m)             │          \u001b[38;5;34m51,200\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ gru_84 (\u001b[38;5;33mGRU\u001b[0m)                         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m21\u001b[0m, \u001b[38;5;34m256\u001b[0m)             │         \u001b[38;5;34m394,752\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ time_distributed_142                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m21\u001b[0m, \u001b[38;5;34m1024\u001b[0m)            │         \u001b[38;5;34m263,168\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)                    │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_71 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m21\u001b[0m, \u001b[38;5;34m1024\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ time_distributed_143                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m21\u001b[0m, \u001b[38;5;34m346\u001b[0m)             │         \u001b[38;5;34m354,650\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)                    │                             │                 │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,063,770</span> (4.06 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,063,770\u001b[0m (4.06 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,063,770</span> (4.06 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,063,770\u001b[0m (4.06 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "embed_rnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "4e973a1b-6584-406b-a561-ae4bb57b30dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 1s/step - accuracy: 0.5561 - loss: 2.2544 - val_accuracy: 0.8272 - val_loss: 0.5272\n",
      "Epoch 2/10\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 1s/step - accuracy: 0.8444 - loss: 0.4816 - val_accuracy: 0.8841 - val_loss: 0.3453\n",
      "Epoch 3/10\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 1s/step - accuracy: 0.8904 - loss: 0.3308 - val_accuracy: 0.9117 - val_loss: 0.2664\n",
      "Epoch 4/10\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 1s/step - accuracy: 0.9093 - loss: 0.2715 - val_accuracy: 0.9205 - val_loss: 0.2337\n",
      "Epoch 5/10\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 1s/step - accuracy: 0.9192 - loss: 0.2392 - val_accuracy: 0.9205 - val_loss: 0.2286\n",
      "Epoch 6/10\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 1s/step - accuracy: 0.9237 - loss: 0.2235 - val_accuracy: 0.9291 - val_loss: 0.2063\n",
      "Epoch 7/10\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 1s/step - accuracy: 0.9286 - loss: 0.2065 - val_accuracy: 0.9305 - val_loss: 0.2015\n",
      "Epoch 8/10\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 1s/step - accuracy: 0.9288 - loss: 0.2052 - val_accuracy: 0.9312 - val_loss: 0.1979\n",
      "Epoch 9/10\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 1s/step - accuracy: 0.9315 - loss: 0.1952 - val_accuracy: 0.9322 - val_loss: 0.1946\n",
      "Epoch 10/10\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 1s/step - accuracy: 0.9318 - loss: 0.1928 - val_accuracy: 0.9351 - val_loss: 0.1867\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1a06784fb50>"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed_rnn_model.fit(X_train, y_train, batch_size=1024, epochs=10, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "3c5975be-4c29-4916-9640-593cb3f4d1b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction:\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 796ms/step\n",
      "new jersey est parfois calme en l' automne et il est neigeux en avril <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "\n",
      "Correct Translation:\n",
      "[\"new jersey est parfois calme pendant l' automne , et il est neigeux en avril .\"]\n",
      "\n",
      "Original text:\n",
      "['new jersey is sometimes quiet during autumn , and it is snowy in april .']\n"
     ]
    }
   ],
   "source": [
    "# Print prediction(s)\n",
    "print(\"Prediction:\")\n",
    "print(logits_to_text(embed_rnn_model.predict(tmp_x[:1])[0], french_tokenizer))\n",
    "\n",
    "print(\"\\nCorrect Translation:\")\n",
    "print(french_sentences[:1])\n",
    "\n",
    "print(\"\\nOriginal text:\")\n",
    "print(english_sentences[:1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "dc1c53ee-161a-4b4c-8a6e-ef0954d7ef1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's try a third model. For RNNs, they cannot see the future input. We can use bidirectional recurrent neural netowrks to see the future and past data.\n",
    "def bd_model(input_shape, output_sequence_length, english_vocab_size, french_vocab_size):\n",
    "    \"\"\"\n",
    "    Build and train a bidirectional RNN model on x and y\n",
    "    param input_shape: Tuple of input shape\n",
    "    param output_sequence_length: Length of output sequence\n",
    "    param english_vocab_size: Number of unique English words in the dataset\n",
    "    param french_vocab_size: Number of unique French words in the dataset\n",
    "    return: Keras model built, but not trained\n",
    "    \"\"\"\n",
    "    learning_rate = 0.003\n",
    "    \n",
    "    #Build the layers\n",
    "    model = Sequential()\n",
    "    model.add(Bidirectional(GRU(128, return_sequences=True), input_shape=input_shape[1:]))\n",
    "    model.add(TimeDistributed(Dense(1024, activation='relu')))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(TimeDistributed(Dense(french_vocab_size, activation='softmax'))) \n",
    "\n",
    "    # Compile model\n",
    "    model.compile(loss=sparse_categorical_crossentropy,\n",
    "                  optimizer=Adam(learning_rate),\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "188ee567-74b1-4746-bfc7-3daafbc32983",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Olurotimi Ajayi\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "test_bd_model(bd_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "be58f533-f7f9-41af-8796-7d26a75d3853",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Reshape the input\n",
    "tmp_x = pad(preproc_english_sentences, preproc_french_sentences.shape[1])\n",
    "tmp_x = tmp_x.reshape((-1, preproc_french_sentences.shape[-2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "2080c8e2-7c43-4a89-bea6-3258014f4820",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(tmp_x, preproc_french_sentences, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "f21afb05-21eb-4047-aa6a-4c06271b23b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Olurotimi Ajayi\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Olurotimi Ajayi\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_78\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_78\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ embedding_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)             │          <span style=\"color: #00af00; text-decoration-color: #00af00\">51,200</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ gru_86 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">394,752</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ time_distributed_146                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">263,168</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)                    │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_73 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ time_distributed_147                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">346</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">354,650</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)                    │                             │                 │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ embedding_15 (\u001b[38;5;33mEmbedding\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m21\u001b[0m, \u001b[38;5;34m256\u001b[0m)             │          \u001b[38;5;34m51,200\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ gru_86 (\u001b[38;5;33mGRU\u001b[0m)                         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m21\u001b[0m, \u001b[38;5;34m256\u001b[0m)             │         \u001b[38;5;34m394,752\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ time_distributed_146                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m21\u001b[0m, \u001b[38;5;34m1024\u001b[0m)            │         \u001b[38;5;34m263,168\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)                    │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_73 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m21\u001b[0m, \u001b[38;5;34m1024\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ time_distributed_147                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m21\u001b[0m, \u001b[38;5;34m346\u001b[0m)             │         \u001b[38;5;34m354,650\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)                    │                             │                 │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,063,770</span> (4.06 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,063,770\u001b[0m (4.06 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,063,770</span> (4.06 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,063,770\u001b[0m (4.06 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TODO: Train and Print prediction(s)\n",
    "embed_rnn_bi_model = embed_model(\n",
    "    tmp_x.shape,\n",
    "    preproc_french_sentences.shape[1],\n",
    "    len(english_tokenizer.word_index)+1,\n",
    "    len(french_tokenizer.word_index)+1)\n",
    "\n",
    "embed_rnn_bi_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "06468fb0-4390-4bf6-9f3d-2801ac55e1f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 1s/step - accuracy: 0.5924 - loss: 2.0202 - val_accuracy: 0.8440 - val_loss: 0.4761\n",
      "Epoch 2/10\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5956s\u001b[0m 69s/step - accuracy: 0.8566 - loss: 0.4356 - val_accuracy: 0.8993 - val_loss: 0.3011\n",
      "Epoch 3/10\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m146s\u001b[0m 2s/step - accuracy: 0.9000 - loss: 0.3006 - val_accuracy: 0.9141 - val_loss: 0.2463\n",
      "Epoch 4/10\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 1s/step - accuracy: 0.9136 - loss: 0.2539 - val_accuracy: 0.9235 - val_loss: 0.2254\n",
      "Epoch 5/10\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 973ms/step - accuracy: 0.9228 - loss: 0.2256 - val_accuracy: 0.9276 - val_loss: 0.2084\n",
      "Epoch 6/10\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 976ms/step - accuracy: 0.9277 - loss: 0.2089 - val_accuracy: 0.9309 - val_loss: 0.2005\n",
      "Epoch 7/10\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 977ms/step - accuracy: 0.9292 - loss: 0.2021 - val_accuracy: 0.9324 - val_loss: 0.1940\n",
      "Epoch 8/10\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 1s/step - accuracy: 0.9318 - loss: 0.1937 - val_accuracy: 0.9325 - val_loss: 0.1948\n",
      "Epoch 9/10\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 1s/step - accuracy: 0.9340 - loss: 0.1864 - val_accuracy: 0.9333 - val_loss: 0.1914\n",
      "Epoch 10/10\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 1s/step - accuracy: 0.9346 - loss: 0.1832 - val_accuracy: 0.9357 - val_loss: 0.1840\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x19eb9621c10>"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed_rnn_bi_model.fit(X_train, y_train, batch_size=1024, epochs=10, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "8becd64d-f846-469f-be12-6ed02c1781b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction:\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "new jersey est parfois calme en l' automne et il est neigeux en avril <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "\n",
      "Correct Translation:\n",
      "[\"new jersey est parfois calme pendant l' automne , et il est neigeux en avril .\"]\n",
      "\n",
      "Original text:\n",
      "['new jersey is sometimes quiet during autumn , and it is snowy in april .']\n"
     ]
    }
   ],
   "source": [
    "# Print prediction(s)\n",
    "print(\"Prediction:\")\n",
    "print(logits_to_text(embed_rnn_bi_model.predict(tmp_x[:1])[0], french_tokenizer))\n",
    "\n",
    "print(\"\\nCorrect Translation:\")\n",
    "print(french_sentences[:1])\n",
    "\n",
    "print(\"\\nOriginal text:\")\n",
    "print(english_sentences[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "34b1e70d-dffb-4088-ba37-c7d95e6f5a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For the 4th model, let's try an encoder-decoder model. The encoder creates a matrix representation kf the sentence and the decoder takes this matrix as input and predicts the translation as output\n",
    "def encdec_model(input_shape, output_sequence_length, english_vocab_size, french_vocab_size):\n",
    "    \"\"\"\n",
    "    Build and train an encoder-decoder model on x and y\n",
    "    :param input_shape: Tuple of input shape\n",
    "    :param output_sequence_length: Length of output sequence\n",
    "    :param english_vocab_size: Number of unique English words in the dataset\n",
    "    :param french_vocab_size: Number of unique French words in the dataset\n",
    "    :return: Keras model built, but not trained\n",
    "    \"\"\"\n",
    "    learning_rate = 0.001\n",
    "    \n",
    "    # Build the layers    \n",
    "    model = Sequential()\n",
    "    # Encoder\n",
    "    model.add(GRU(256, input_shape=input_shape[1:], go_backwards=True))\n",
    "    model.add(RepeatVector(output_sequence_length))\n",
    "    # Decoder\n",
    "    model.add(GRU(256, return_sequences=True))\n",
    "    model.add(TimeDistributed(Dense(1024, activation='relu')))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(TimeDistributed(Dense(french_vocab_size, activation='softmax')))\n",
    "\n",
    "    # Compile model\n",
    "    model.compile(loss=sparse_categorical_crossentropy,\n",
    "                  optimizer=Adam(learning_rate),\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "993ef7ec-aff5-4029-a5b0-1781a2bad66a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Olurotimi Ajayi\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "test_encdec_model(encdec_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "d35b0fe7-573d-4980-99a5-293222215a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the input\n",
    "tmp_x = pad(preproc_english_sentences, preproc_french_sentences.shape[1])\n",
    "tmp_x = tmp_x.reshape((-1, preproc_french_sentences.shape[-2], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "b8e6f46d-7650-4505-868d-77f7a518ef52",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(tmp_x, preproc_french_sentences, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "bd7a035d-b98d-4888-837f-f49755517fc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_80\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_80\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ gru_89 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">198,912</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ repeat_vector_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">RepeatVector</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ gru_90 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">394,752</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ time_distributed_150                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">263,168</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)                    │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_75 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ time_distributed_151                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">346</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">354,650</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)                    │                             │                 │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ gru_89 (\u001b[38;5;33mGRU\u001b[0m)                         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │         \u001b[38;5;34m198,912\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ repeat_vector_9 (\u001b[38;5;33mRepeatVector\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m21\u001b[0m, \u001b[38;5;34m256\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ gru_90 (\u001b[38;5;33mGRU\u001b[0m)                         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m21\u001b[0m, \u001b[38;5;34m256\u001b[0m)             │         \u001b[38;5;34m394,752\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ time_distributed_150                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m21\u001b[0m, \u001b[38;5;34m1024\u001b[0m)            │         \u001b[38;5;34m263,168\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)                    │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_75 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m21\u001b[0m, \u001b[38;5;34m1024\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ time_distributed_151                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m21\u001b[0m, \u001b[38;5;34m346\u001b[0m)             │         \u001b[38;5;34m354,650\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)                    │                             │                 │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,211,482</span> (4.62 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,211,482\u001b[0m (4.62 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,211,482</span> (4.62 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,211,482\u001b[0m (4.62 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create the model and display its summary\n",
    "encdec_rnn_model = encdec_model(tmp_x.shape,preproc_french_sentences.shape[1],len(english_tokenizer.word_index)+1,len(french_tokenizer.word_index)+1)\n",
    "encdec_rnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "c83d7f8f-0769-4b67-8289-48727df00cc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 1s/step - accuracy: 0.4039 - loss: 3.2776 - val_accuracy: 0.5364 - val_loss: 1.9052\n",
      "Epoch 2/10\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 1s/step - accuracy: 0.5432 - loss: 1.8551 - val_accuracy: 0.5749 - val_loss: 1.5639\n",
      "Epoch 3/10\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 1s/step - accuracy: 0.5866 - loss: 1.5576 - val_accuracy: 0.6182 - val_loss: 1.3848\n",
      "Epoch 4/10\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 1s/step - accuracy: 0.6139 - loss: 1.4084 - val_accuracy: 0.6400 - val_loss: 1.3179\n",
      "Epoch 5/10\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 1s/step - accuracy: 0.6296 - loss: 1.3384 - val_accuracy: 0.6499 - val_loss: 1.2612\n",
      "Epoch 6/10\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 1s/step - accuracy: 0.6421 - loss: 1.2824 - val_accuracy: 0.6564 - val_loss: 1.2138\n",
      "Epoch 7/10\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 1s/step - accuracy: 0.6516 - loss: 1.2381 - val_accuracy: 0.6650 - val_loss: 1.1678\n",
      "Epoch 8/10\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 1s/step - accuracy: 0.6599 - loss: 1.1938 - val_accuracy: 0.6654 - val_loss: 1.1601\n",
      "Epoch 9/10\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 1s/step - accuracy: 0.6617 - loss: 1.1827 - val_accuracy: 0.6731 - val_loss: 1.1232\n",
      "Epoch 10/10\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 1s/step - accuracy: 0.6709 - loss: 1.1422 - val_accuracy: 0.6751 - val_loss: 1.1164\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1a055d86cd0>"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encdec_rnn_model.fit(X_train, y_train, batch_size=1024, epochs=10, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "8785c2ae-2f26-4233-ab00-0f202dd6c186",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction:\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "new jersey est parfois agrã©able en l' et il est est en en <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "\n",
      "Correct Translation:\n",
      "[\"new jersey est parfois calme pendant l' automne , et il est neigeux en avril .\"]\n",
      "\n",
      "Original text:\n",
      "['new jersey is sometimes quiet during autumn , and it is snowy in april .']\n"
     ]
    }
   ],
   "source": [
    "# Print prediction(s)\n",
    "print(\"Prediction:\")\n",
    "print(logits_to_text(encdec_rnn_model.predict(tmp_x[:1])[0], french_tokenizer))\n",
    "\n",
    "print(\"\\nCorrect Translation:\")\n",
    "print(french_sentences[:1])\n",
    "\n",
    "print(\"\\nOriginal text:\")\n",
    "print(english_sentences[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dcd6496f-6f5e-4047-975b-72c1629bb988",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we will try a model where we incorporate embedding and biderectional rnns into our model\n",
    "def model_final(input_shape, output_sequence_length, english_vocab_size, french_vocab_size):\n",
    "    \"\"\"\n",
    "    Build and train a model that incorporates embedding, encoder-decoder, and bidirectional RNN on x and y\n",
    "    :param input_shape: Tuple of input shape\n",
    "    :param output_sequence_length: Length of output sequence\n",
    "    :param english_vocab_size: Number of unique English words in the dataset\n",
    "    :param french_vocab_size: Number of unique French words in the dataset\n",
    "    :return: Keras model built, but not trained\n",
    "    \"\"\"\n",
    "    learning_rate = 0.003\n",
    "    \n",
    "    # Build the layers    \n",
    "    model = Sequential()\n",
    "    # Embedding\n",
    "    model.add(Embedding(english_vocab_size, 128, input_length=input_shape[1],\n",
    "                         input_shape=input_shape[1:]))\n",
    "    # Encoder\n",
    "    model.add(Bidirectional(GRU(128)))\n",
    "    model.add(RepeatVector(output_sequence_length))\n",
    "    # Decoder\n",
    "    model.add(Bidirectional(GRU(128, return_sequences=True)))\n",
    "    model.add(TimeDistributed(Dense(512, activation='relu')))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(TimeDistributed(Dense(french_vocab_size, activation='softmax')))\n",
    "    model.compile(loss=sparse_categorical_crossentropy,\n",
    "                  optimizer=Adam(learning_rate),\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "15b57e94-8236-4280-914a-b7066e32971b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Olurotimi Ajayi\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_model_final(model_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5c483888-d4a1-4650-af37-2b9d8a750d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(preproc_english_sentences, preproc_french_sentences, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "91c62520-7f2f-477b-be88-36094da9d476",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, 15, 128)           25600     \n",
      "                                                                 \n",
      " bidirectional_2 (Bidirecti  (None, 256)               198144    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " repeat_vector_1 (RepeatVec  (None, 21, 256)           0         \n",
      " tor)                                                            \n",
      "                                                                 \n",
      " bidirectional_3 (Bidirecti  (None, 21, 256)           296448    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " time_distributed_2 (TimeDi  (None, 21, 512)           131584    \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 21, 512)           0         \n",
      "                                                                 \n",
      " time_distributed_3 (TimeDi  (None, 21, 346)           177498    \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 829274 (3.16 MB)\n",
      "Trainable params: 829274 (3.16 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Train neural network using model_final\n",
    "model = model_final(preproc_english_sentences.shape,preproc_french_sentences.shape[1],len(english_tokenizer\t.word_index)+1,len(french_tokenizer.word_index)+1)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "01ce25b1-9c84-40a2-98a5-4016dc22c9e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "WARNING:tensorflow:From C:\\Users\\Olurotimi Ajayi\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Olurotimi Ajayi\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "87/87 [==============================] - 69s 658ms/step - loss: 2.8757 - accuracy: 0.4322 - val_loss: 1.9452 - val_accuracy: 0.5139\n",
      "Epoch 2/25\n",
      "87/87 [==============================] - 55s 629ms/step - loss: 1.6985 - accuracy: 0.5682 - val_loss: 1.5050 - val_accuracy: 0.5925\n",
      "Epoch 3/25\n",
      "87/87 [==============================] - 54s 627ms/step - loss: 1.3559 - accuracy: 0.6360 - val_loss: 1.1318 - val_accuracy: 0.6782\n",
      "Epoch 4/25\n",
      "87/87 [==============================] - 56s 639ms/step - loss: 1.1565 - accuracy: 0.6736 - val_loss: 1.0241 - val_accuracy: 0.7069\n",
      "Epoch 5/25\n",
      "87/87 [==============================] - 59s 676ms/step - loss: 0.9965 - accuracy: 0.7077 - val_loss: 0.8862 - val_accuracy: 0.7279\n",
      "Epoch 6/25\n",
      "87/87 [==============================] - 57s 660ms/step - loss: 0.9291 - accuracy: 0.7220 - val_loss: 0.7653 - val_accuracy: 0.7660\n",
      "Epoch 7/25\n",
      "87/87 [==============================] - 58s 666ms/step - loss: 0.7844 - accuracy: 0.7578 - val_loss: 0.6657 - val_accuracy: 0.7923\n",
      "Epoch 8/25\n",
      "87/87 [==============================] - 58s 662ms/step - loss: 0.6790 - accuracy: 0.7861 - val_loss: 0.5440 - val_accuracy: 0.8283\n",
      "Epoch 9/25\n",
      "87/87 [==============================] - 59s 673ms/step - loss: 0.5851 - accuracy: 0.8140 - val_loss: 0.5242 - val_accuracy: 0.8354\n",
      "Epoch 10/25\n",
      "87/87 [==============================] - 58s 671ms/step - loss: 0.6334 - accuracy: 0.8028 - val_loss: 0.4198 - val_accuracy: 0.8685\n",
      "Epoch 11/25\n",
      "87/87 [==============================] - 57s 660ms/step - loss: 0.4506 - accuracy: 0.8571 - val_loss: 0.4038 - val_accuracy: 0.8749\n",
      "Epoch 12/25\n",
      "87/87 [==============================] - 57s 660ms/step - loss: 0.3984 - accuracy: 0.8740 - val_loss: 0.3264 - val_accuracy: 0.8984\n",
      "Epoch 13/25\n",
      "87/87 [==============================] - 56s 646ms/step - loss: 0.4603 - accuracy: 0.8552 - val_loss: 0.2963 - val_accuracy: 0.9108\n",
      "Epoch 14/25\n",
      "87/87 [==============================] - 58s 662ms/step - loss: 0.3141 - accuracy: 0.9026 - val_loss: 0.2386 - val_accuracy: 0.9320\n",
      "Epoch 15/25\n",
      "87/87 [==============================] - 58s 667ms/step - loss: 0.2661 - accuracy: 0.9203 - val_loss: 0.1939 - val_accuracy: 0.9471\n",
      "Epoch 16/25\n",
      "87/87 [==============================] - 64s 740ms/step - loss: 0.2331 - accuracy: 0.9319 - val_loss: 0.1746 - val_accuracy: 0.9529\n",
      "Epoch 17/25\n",
      "87/87 [==============================] - 57s 661ms/step - loss: 0.2117 - accuracy: 0.9381 - val_loss: 0.1594 - val_accuracy: 0.9553\n",
      "Epoch 18/25\n",
      "87/87 [==============================] - 58s 666ms/step - loss: 0.1866 - accuracy: 0.9454 - val_loss: 0.1415 - val_accuracy: 0.9600\n",
      "Epoch 19/25\n",
      "87/87 [==============================] - 55s 632ms/step - loss: 0.1715 - accuracy: 0.9498 - val_loss: 0.1396 - val_accuracy: 0.9599\n",
      "Epoch 20/25\n",
      "87/87 [==============================] - 56s 646ms/step - loss: 0.1589 - accuracy: 0.9532 - val_loss: 0.1289 - val_accuracy: 0.9635\n",
      "Epoch 21/25\n",
      "87/87 [==============================] - 56s 644ms/step - loss: 0.1502 - accuracy: 0.9553 - val_loss: 0.1142 - val_accuracy: 0.9672\n",
      "Epoch 22/25\n",
      "87/87 [==============================] - 58s 662ms/step - loss: 0.2638 - accuracy: 0.9205 - val_loss: 0.1242 - val_accuracy: 0.9645\n",
      "Epoch 23/25\n",
      "87/87 [==============================] - 57s 657ms/step - loss: 0.1374 - accuracy: 0.9598 - val_loss: 0.1059 - val_accuracy: 0.9686\n",
      "Epoch 24/25\n",
      "87/87 [==============================] - 57s 657ms/step - loss: 0.1219 - accuracy: 0.9638 - val_loss: 0.1011 - val_accuracy: 0.9705\n",
      "Epoch 25/25\n",
      "87/87 [==============================] - 58s 664ms/step - loss: 0.1164 - accuracy: 0.9656 - val_loss: 0.1045 - val_accuracy: 0.9703\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2258ac941d0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size=1024, epochs=25, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9d506980-65df-42df-959a-c55550850f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('Translator Model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bbc2319e-8504-4728-8295-c720be02f5a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224bdf15-7f1c-471d-9f89-7608fae12fbb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
